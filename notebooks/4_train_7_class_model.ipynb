{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6acfc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import (\n",
    "    RandomForestClassifier, \n",
    "    LogisticRegression, \n",
    "    NaiveBayes,\n",
    ")\n",
    "#from sparkxgb.classifier import XGBoostClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import PipelineModel\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c33ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = \"C:/Users/rwkos/miniconda3/envs/music_classifier/python.exe\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = \"C:/Users/rwkos/miniconda3/envs/music_classifier/python.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f69437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop any existing Spark context\n",
    "try:\n",
    "    spark.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Music_Classifier\") \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"false\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac415535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned dataset\n",
    "df_train = spark.read.csv(\"./notebook_data/Mendeley_cleaned_train.csv\", header=True, inferSchema=True)\n",
    "df_test = spark.read.csv(\"./notebook_data/Mendeley_cleaned_test.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4cd87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under sampling train data\n",
    "\n",
    "# min_count = df_train.groupBy(\"genre\").count().agg({\"count\": \"min\"}).collect()[0][0]\n",
    "# print(f\"The smallest class has {min_count} songs. Sample other classes to match this.\")\n",
    "\n",
    "# genres = [row['genre'] for row in df_train.select('genre').distinct().collect()]\n",
    "\n",
    "# balanced_df_list = []\n",
    "# for genre in genres:\n",
    "#     subset = df_train.where(df_train.genre == genre)\n",
    "    \n",
    "#     # If the class is larger than the smallest class, sample it down\n",
    "#     if subset.count() > min_count:\n",
    "#         # Calculate the fraction needed for sampling\n",
    "#         sample_fraction = min_count / subset.count()\n",
    "#         sampled_subset = subset.sample(withReplacement=False, fraction=sample_fraction, seed=42)\n",
    "#         balanced_df_list.append(sampled_subset)\n",
    "#     else:\n",
    "#         # If it's the smallest class, keep all of it\n",
    "#         balanced_df_list.append(subset)\n",
    "\n",
    "# # Combine the balanced subsets into a single DataFrame\n",
    "# df_train_balanced = reduce(DataFrame.unionAll, balanced_df_list)\n",
    "\n",
    "# print(\"New balanced dataset counts:\")\n",
    "# df_train_balanced.groupBy(\"genre\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85cb95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature pipeline\n",
    "pipeline_model = PipelineModel.load(\"./notebook_data/feature_pipeline_lyrics_only\")\n",
    "\n",
    "# Apply the feature engineering pipeline\n",
    "#df_train_transformed = pipeline_model.transform(df_train_balanced)\n",
    "df_train_transformed = pipeline_model.transform(df_train)\n",
    "df_test_transformed = pipeline_model.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1324def",
   "metadata": {},
   "source": [
    "# Model Training And Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119df2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", seed=42),\n",
    "    \"Logistic Regression\": LogisticRegression(featuresCol=\"features\", labelCol=\"label\"),\n",
    "    \"Naive Bayes\": NaiveBayes(featuresCol=\"features\", labelCol=\"label\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17138dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926f0a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    print(\"---\" * 15)\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Train the model on the balanced training data\n",
    "    fitted_model = model.fit(df_train_transformed)\n",
    "    \n",
    "    # Make predictions on the untouched test data\n",
    "    preds = fitted_model.transform(df_test_transformed)\n",
    "    \n",
    "    # Calculate the F1 score\n",
    "    f1_score = evaluator.evaluate(preds)\n",
    "    \n",
    "    print(f\" F1-Score for {name}: {f1_score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3afb1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from functools import reduce\n",
    "\n",
    "# Import PySpark tools and the native GBTClassifier\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import GBTClassifier, OneVsRest\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "class_counts = df_train_transformed.groupBy(\"label\").count()\n",
    "\n",
    "total_samples = df_train_transformed.count()\n",
    "num_classes = class_counts.count()\n",
    "\n",
    "class_weights = class_counts.withColumn(\"weight\", total_samples / (num_classes * col(\"count\")))\n",
    "\n",
    "train_with_weights = df_train_transformed.join(class_weights, \"label\", \"left\")\n",
    "\n",
    "\n",
    "gbt = GBTClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "ovr = OneVsRest(\n",
    "    classifier=gbt,\n",
    "    weightCol=\"weight\" \n",
    ")\n",
    "\n",
    "print(\"\\\\n--- Training One-vs-Rest with GBTClassifier and Class Weights ---\")\n",
    "\n",
    "ovr_model = ovr.fit(train_with_weights)\n",
    "\n",
    "preds = ovr_model.transform(df_test_transformed)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluator.evaluate(preds)\n",
    "\n",
    "print(f\"F1-Score for GBTClassifier (One-vs-Rest): {f1:.4f}\\\\n\")\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914ee398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "# rf_model.save(\"./notebook_data/rf_7class_model_lyrics_only\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music_classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
